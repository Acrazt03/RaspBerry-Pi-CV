{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyRdDYkqAKN4"
      },
      "source": [
        "## Before you start\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cDtxLIBHgQ",
        "outputId": "1c1c9afb-e461-4790-8d50-135f090f79c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sat Feb 11 18:50:55 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 527.56       Driver Version: 527.56       CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
            "|  0%   45C    P8    18W / 170W |   1304MiB / 12288MiB |      7%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1088    C+G   ...ext\\CNext\\AMDRSSrcExt.exe    N/A      |\n",
            "|    0   N/A  N/A      3696    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
            "|    0   N/A  N/A      4704    C+G   ...v1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
            "|    0   N/A  N/A      5008    C+G   ...8bbwe\\Microsoft.Notes.exe    N/A      |\n",
            "|    0   N/A  N/A      6248    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A      6924    C+G   ...wekyb3d8bbwe\\Music.UI.exe    N/A      |\n",
            "|    0   N/A  N/A      7480    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A      7632    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A     10500    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
            "|    0   N/A  N/A     10704    C+G   ...e\\PhoneExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A     11404    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A     12140    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
            "|    0   N/A  N/A     12960    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
            "|    0   N/A  N/A     13884    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     13896    C+G   ...ontend\\Docker Desktop.exe    N/A      |\n",
            "|    0   N/A  N/A     14156    C+G   ...\\CNext\\RadeonSoftware.exe    N/A      |\n",
            "|    0   N/A  N/A     14736    C+G   ...obeNotificationClient.exe    N/A      |\n",
            "|    0   N/A  N/A     15156    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
            "|    0   N/A  N/A     17668    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "|    0   N/A  N/A     18944    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjpPg4mGKc1v",
        "outputId": "ad61f0df-d407-46f5-b78b-63715f659257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Acrazt04\\Documents\\Products\\OpenCV course\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C3EO_2zNChu"
      },
      "source": [
        "## Install YOLOv8\n",
        "\n",
        "‚ö†Ô∏è YOLOv8 is still under heavy development. Breaking changes are being introduced almost weekly. We strive to make our YOLOv8 notebooks work with the latest version of the library. Last tests took place on **18.01.2023** with version **YOLOv8.0.9**.\n",
        "\n",
        "If you notice that our notebook behaves incorrectly - especially if you experience errors that prevent you from going through the tutorial - don't hesitate! Let us know and open an [issue](https://github.com/roboflow/notebooks/issues) on the Roboflow Notebooks repository.\n",
        "\n",
        "YOLOv8 can be installed in two ways‚Ää-‚Ääfrom the source and via pip. This is because it is the first iteration of YOLO to have an official package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdSMcABDNKW-",
        "outputId": "44bf5b63-c4b8-4b5d-81c1-f4d3458b8ae1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.34  Python-3.10.9 torch-1.13.1+cpu CPU\n",
            "Setup complete  (12 CPUs, 15.9 GB RAM, 580.4/637.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# Pip install method (recommended)\n",
        "\n",
        "!pip install ultralytics==8.0.20\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VOEYrlBoP9-E"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnnZSm5OQfPQ"
      },
      "source": [
        "## CLI Basics "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5RGYA6sPgEd"
      },
      "source": [
        "## Inference with Pre-trained COCO Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT1qD4toTTw0"
      },
      "source": [
        "### üíª CLI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaE1kLS8R4CV"
      },
      "source": [
        "`yolo mode=predict` runs YOLOv8 inference on a variety of sources, downloading models automatically from the latest YOLOv8 release, and saving results to `runs/predict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDbMt_M6PiXb",
        "outputId": "bf95fa06-55f8-49fd-8889-702dc388b841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Acrazt04\\Documents\\Products\\OpenCV course\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING  Ultralytics settings reset to defaults. \n",
            "This is normal and may be due to a recent ultralytics package update, but may have overwritten previous settings. \n",
            "You may view and update settings directly in 'C:\\Users\\Acrazt04\\AppData\\Roaming\\Ultralytics\\settings.yaml'\n",
            "Ultralytics YOLOv8.0.20  Python-3.10.9 torch-1.13.1+cpu CPU\n",
            "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
            "Found https://media.roboflow.com/notebooks/examples/dog.jpeg locally at dog.jpeg\n",
            "image 1/1 C:\\Users\\Acrazt04\\Documents\\Products\\OpenCV course\\dog.jpeg: 640x384 1 person, 1 car, 1 dog, 1 backpack, 1 handbag, 169.0ms\n",
            "Speed: 1.0ms pre-process, 169.0ms inference, 4.0ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "!yolo task=segment mode=predict model=yolov8s-seg.pt conf=0.25 source='https://media.roboflow.com/notebooks/examples/dog.jpeg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "LyopYpK1TQrB",
        "outputId": "e4ed4494-c9b4-4d3b-b787-cf178960359b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Acrazt04\\Documents\\Products\\OpenCV course\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'runs/segment/predict/dog.jpeg'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mcd\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m{HOME}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m Image(filename\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mruns/segment/predict/dog.jpeg\u001b[39;49m\u001b[39m'\u001b[39;49m, height\u001b[39m=\u001b[39;49m\u001b[39m600\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munconfined \u001b[39m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malt \u001b[39m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[39msuper\u001b[39;49m(Image, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(data\u001b[39m=\u001b[39;49mdata, url\u001b[39m=\u001b[39;49murl, filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m    971\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata)\n\u001b[0;32m    973\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39m=\u001b[39m metadata[\u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreload()\n\u001b[0;32m    328\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_data()\n",
            "File \u001b[1;32mc:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[39msuper\u001b[39;49m(Image,\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mreload()\n\u001b[0;32m   1006\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retina_shape()\n",
            "File \u001b[1;32mc:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_flags \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_flags, encoding\u001b[39m=\u001b[39;49mencoding) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[39m# Deferred import\u001b[39;00m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/segment/predict/dog.jpeg'"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "Image(filename='runs/segment/predict/dog.jpeg', height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFMBYQtMVL-B"
      },
      "source": [
        "### üêç Python SDK\n",
        "\n",
        "The simplest way of simply using YOLOv8 directly in a Python environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"FCnmWTeWVxxqR2PoLjM0\")\n",
        "project = rf.workspace(\"vinicio-arturo-castillo-castillo-ad1oc\").project(\"filtro-mangera-dataset-v1\")\n",
        "dataset = project.version(1).download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QkNDZaVyHip",
        "outputId": "15cfd0f3-02ea-4bb2-f86b-435032709695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Acrazt04\\Documents\\Products\\OpenCV course\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dependency ultralytics<=8.0.20 is required but found version=8.0.34, to fix: `pip install ultralytics<=8.0.20`\n",
            "Downloading Dataset Version Zip in Filtro-Mangera-Dataset-v1-2 to yolov8: 100% [3702394 / 3702394] bytes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Dataset Version Zip to Filtro-Mangera-Dataset-v1-2 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 236/236 [00:00<00:00, 2842.77it/s]\n"
          ]
        }
      ],
      "source": [
        "#%cd {HOME}\n",
        "\n",
        "#!pip install roboflow --quiet\n",
        "\n",
        "#from roboflow import Roboflow\n",
        "#rf = Roboflow(api_key=\"FCnmWTeWVxxqR2PoLjM0\")\n",
        "#project = rf.workspace(\"vinicio-arturo-castillo-castillo-ad1oc\").project(\"filtro-mangera-dataset-v1\")\n",
        "#dataset = project.version(2).download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUjFBKKqXa-u"
      },
      "source": [
        "## Custom Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjfrjlikzGkx",
        "outputId": "7fa19d52-5b42-47f1-9278-2e8033775f10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Acrazt04\\Documents\\Products\\OpenCV course\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.34  Python-3.10.9 torch-1.13.1+cpu CPU\n",
            "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=segment, mode=train, model=yolov8s-seg.pt, data=Filtro-Mangera-Dataset-v1-2\\data.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, min_memory=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, split=val, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.6, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs\\segment\\train5\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py\", line 124, in __init__\n",
            "    self.data = check_det_dataset(self.args.data)\n",
            "  File \"C:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\site-packages\\ultralytics\\yolo\\data\\utils.py\", line 240, in check_det_dataset\n",
            "    raise FileNotFoundError(msg)\n",
            "FileNotFoundError: \n",
            "Dataset 'Filtro-Mangera-Dataset-v1-2\\data.yaml' not found ‚ö†Ô∏è, missing paths ['C:\\\\Users\\\\Acrazt04\\\\Documents\\\\Products\\\\OpenCV course\\\\datasets\\\\Filtro-Mangera-Dataset-v1-2\\\\Filtro-Mangera-Dataset-v1-2\\\\valid\\\\images']\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"C:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"C:\\Users\\Acrazt04\\anaconda3\\envs\\test\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
            "  File \"C:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\site-packages\\ultralytics\\yolo\\cfg\\__init__.py\", line 300, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"C:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 215, in train\n",
            "    self.trainer = self.TrainerClass(overrides=overrides)\n",
            "  File \"C:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\site-packages\\ultralytics\\yolo\\v8\\segment\\train.py\", line 24, in __init__\n",
            "    super().__init__(cfg, overrides)\n",
            "  File \"C:\\Users\\Acrazt04\\anaconda3\\envs\\test\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py\", line 128, in __init__\n",
            "    raise FileNotFoundError(emojis(f\"Dataset '{self.args.data}' error ‚ùå {e}\")) from e\n",
            "FileNotFoundError: Dataset 'Filtro-Mangera-Dataset-v1-2\\data.yaml' error  \n",
            "Dataset 'Filtro-Mangera-Dataset-v1-2\\data.yaml' not found , missing paths ['C:\\\\Users\\\\Acrazt04\\\\Documents\\\\Products\\\\OpenCV course\\\\datasets\\\\Filtro-Mangera-Dataset-v1-2\\\\Filtro-Mangera-Dataset-v1-2\\\\valid\\\\images']\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}\n",
        "\n",
        "!yolo task=segment mode=train model=yolov8s-seg.pt data={dataset.location}/data.yaml epochs=100 imgsz=640"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "ebb0d029462db9bfbba54714c60574f9637f83dbf43ec21a8d31b8319d9b3fbd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
